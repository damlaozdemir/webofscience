(dp1
S'output'
p2
S"<type 'exceptions.TypeError'> unsupported operand type(s) for -: 'NoneType' and 'int'"
p3
sS'layer'
p4
S'/home/damla/web2py/applications/webofscience/controllers/default.py'
p5
sS'code'
p6
S'from urllib2 import *\nimport urllib\nimport collections\nimport itertools\nfrom gluon.serializers import json\nimport math\n\n\ndef index():\n    session.keyword = str(request.vars.inputkeyword)\n    if(session.keyword == "None"):\n        session.keyword = "*"\n    else:\n        session.keyword = str(request.vars.inputkeyword)\n    \n    f = { \'q\' : session.keyword}\n    if(request.vars.page == \'None\'):\n        page=1\n    else:\n        page = request.vars.page\n    print page\n    \n    facetoffset = (page-1)*20\n    facetlimit=facetoffset+20\n    connection = urlopen(\'http://localhost:8983/solr/webofscienceindex/select?\'+urllib.urlencode(f)+\'&rows=2000&wt=json&indent=true&facet=true&facet.field=authors&facet.field=published&facet.mincount=1&facet.limit=\'+str(facetlimit)+\'&facet.offset=\'+str(facetoffset))\n    response = eval(connection.read())\n\n    articles = response[\'response\'][\'docs\']\n    facet = response[\'facet_counts\'][\'facet_fields\']\n    \n    authorArticles =[]\n    totalArticles = []\n    facetList =[]\n    for f in facet[\'authors\']:\n        if(facet[\'authors\'].index(f) %2 == 0):\n            authorArticles.append(f)\n        else:\n            totalArticles.append(f)\n    facetList.append(authorArticles)\n    facetList.append(totalArticles)\n    length = len(facetList[0])\n    \n    mydict = {}\n    for i in range(len(facetList[0])):\n        cot = ("\\"","\\"")\n        authorname = facetList[0][i].join(cot)\n        f = { \'q\' : session.keyword, \'fq\' : "authors:"+authorname}\n       # print session.keyword\n       # print authorname\n        connection2 = urlopen(\'http://localhost:8983/solr/webofscienceindex/select?\'+urllib.urlencode(f)+\'&start=0&rows=10&wt=json&indent=true&facet=true&facet.field=authors&facet.field=published&facet.mincount=1&facet.limit=100\')\n        response2 = eval(connection2.read())\n        articles = response2[\'response\'][\'docs\']\n        uniquekeywords = []\n        for article in articles:\n            keywords = []\n            if \'keywords\' in article :\n                for keyword in article[\'keywords\']:\n                    keywords.append(keyword.lower())\n            keywordsplus = []\n            if \'keywordsplus\' in article :\n                for keywordplus in article[\'keywordsplus\']:\n                    keywordsplus.append(keywordplus.lower())\n            totalkeywords = itertools.chain(keywords, keywordsplus)\n            for keywords in totalkeywords:\n                uniquekeywords.append(keywords)\n            keywordcomplete = json(set(uniquekeywords))\n        #authors and total keywords dictionary    \n        if facetList[0][i] in mydict:\n            mydict[facetList[0][i]] += keywordcomplete\n        else:\n            mydict[facetList[0][i]] = keywordcomplete\n    \n    mydict = collections.OrderedDict(sorted(mydict.items()))\n    #print mydict\n    \n        \n    \n    #Autocomplete#\n    uniquekeywords = []\n    for article in articles:\n        keywords = []\n        if \'keywords\' in article :\n            for keyword in article[\'keywords\']:\n                keywords.append(keyword.lower())\n        keywordsplus = []\n        if \'keywordsplus\' in article :\n            for keywordplus in article[\'keywordsplus\']:\n                keywordsplus.append(keywordplus.lower())\n        totalkeywords = itertools.chain(keywords, keywordsplus)\n        for keywords in totalkeywords:\n            uniquekeywords.append(keywords)\n        keywordcomplete = json(set(uniquekeywords))\n\n\n    return dict(keyword =session.keyword, facetList=facetList, length = length,  articles=articles, keywordcomplete = json(set(uniquekeywords)))\n\ndef author():\n\n    keyword2 = session.keyword\n    \n    authorrequest = request.args[0]\n    authorname = authorrequest.replace(\'__\', \', \')\n    athname = session.authorname\n    cot = ("\\"","\\"")\n    authorname = authorname.join(cot)\n\n    f = { \'q\' : keyword2, \'fq\' : "authors:"+authorname}\n    urlname = urllib.urlencode(f)\n    connection = urlopen(\'http://localhost:8983/solr/webofscienceindex/select?\'+urllib.urlencode(f)+\'&rows=20000&wt=json&indent=true&facet=true&facet.field=authors&facet.field=published&facet.mincount=1&facet.limit=100\')\n    response = eval(connection.read())\n    matches = response[\'response\'][\'numFound\']\n    articles = response[\'response\'][\'docs\']\n    facet = response[\'facet_counts\'][\'facet_fields\']\n    #articles = sorted(articles, key=lambda k: k [\'published\'][0], reverse= True)\n    articlesList = []\n    puclisheddates = []\n    for a in articles:\n        article = {}\n        #p = a[\'published\'][0]\n        #new[\'published\'] = p\n        #article[\'authors\'] = a[0][0]\n        article[\'title\'] = a[\'title\'][0]\n        #article[\'abstract\'] = a[2][0]\n        #article[\'keywords\'] = a[\'keywords\'][0]\n        #article[\'address\'] = a[\'revisedAddress\'][0]\n        #dates.append(d)\n        articlesList.append(article)\n    #dates = list(set(dates)) # coklu degerleri uniqe yapar\n    length = len(articlesList[0])\n\n    years =[]\n    numofpub = []\n    facetListyears =[]\n    facetList =[]\n    for f in facet[\'published\']:\n        if(facet[\'published\'].index(f) %2 == 0):\n            years.append(f[-4:])\n        else:\n            numofpub.append(f)\n    facetListyears.append(years)\n    facetListyears.append(numofpub)\n    #lengthofyears = len(facetList[0])\n    mydict = {}\n    for i in range(len(facetListyears[0])):\n        if facetListyears[0][i] in mydict:\n            mydict[facetListyears[0][i]] += facetListyears[1][i]\n        else:\n            mydict[facetListyears[0][i]] = facetListyears[1][i]\n    \n    mydict = collections.OrderedDict(sorted(mydict.items()))\n\n    #Autocomplete#\n    uniquekeywords = []\n    for article in articles:\n        keywords = []\n        if \'keywords\' in article :\n            for keyword in article[\'keywords\']:\n                keywords.append(keyword.lower())\n        keywordsplus = []\n        if \'keywordsplus\' in article :\n            for keywordplus in article[\'keywordsplus\']:\n                keywordsplus.append(keywordplus.lower())\n        totalkeywords = itertools.chain(keywords, keywordsplus)\n        for keywords in totalkeywords:\n            uniquekeywords.append(keywords)\n        keywordcomplete = json(set(uniquekeywords))\n    return dict(articlesList = articlesList, articles=articles, keyword =keyword2, matches=matches,urlname=urlname,authorname=authorname,length=length, athname=athname ,facetListyears=facetListyears, mydict=mydict, keywordcomplete = json(set(uniquekeywords)))\n\nresponse._vars=response._caller(index)\n'
p7
sS'snapshot'
p8
(dp9
sS'traceback'
p10
S'Traceback (most recent call last):\n  File "/home/damla/web2py/gluon/restricted.py", line 227, in restricted\n    exec ccode in environment\n  File "/home/damla/web2py/applications/webofscience/controllers/default.py", line 169, in <module>\n  File "/home/damla/web2py/gluon/globals.py", line 417, in <lambda>\n    self._caller = lambda f: f()\n  File "/home/damla/web2py/applications/webofscience/controllers/default.py", line 23, in index\n    facetoffset = (page-1)*20\nTypeError: unsupported operand type(s) for -: \'NoneType\' and \'int\'\n'
p11
s.